{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 1 and 2\n",
      "3\n",
      "3\n",
      "add 3 and 4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# What does lru_cache do?\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(1)\n",
    "def addxy(x, y):\n",
    "    print('add {} and {}'.format(x, y))\n",
    "    return x+y\n",
    "\n",
    "print(addxy(1, 2))\n",
    "print(addxy(1, 2))\n",
    "print(addxy(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CandidateInfoTuple = namedtuple(\n",
    "'CandidateInfoTuple', # this namedtuple's name\n",
    "'isNodule_bool, diameter_mm, series_uid, center_xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name of .mhd file I downloaded and store these information in cache\n",
    "# no return, just store\n",
    "requireOnDisk_bool = True\n",
    "@lru_cache(1)\n",
    "def getCandidateInfoList(requireOnDisk_bool=requireOnDisk_bool):\n",
    "    # a default parameter of this function\n",
    "    mhd_list = glob.glob('./luna16/data/subset0/*.mhd')\n",
    "    # mhd_list is a list of file paths, like '/subset7/534991.mhd'\n",
    "    # os.path.split(p) returns a list of os.path and p, [path, p]\n",
    "    # -1 we get p, and :-4 we drop .mhd and get only the name\n",
    "    presentOnDisk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "    return(presentOnDisk_set)\n",
    "\n",
    "presentOnDisk_set = getCandidateInfoList(requireOnDisk_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about diameter for each id\n",
    "diameter_dict = {}\n",
    "with open('./luna16/data/annotations.csv') as f:\n",
    "    # csv.reader: read f in csv version, so row is a list of each element\n",
    "    # 1: because the first row is header\n",
    "    for row in list(csv.reader(f))[1:]:\n",
    "        series_uid = row[0]\n",
    "        annotationCenter_xyz = tuple(float(x) for x in row[1:4])\n",
    "        annotationDiameter_mm = float(row[4])\n",
    "        # dict.setdefault(a, b): if a is in dict, then return dict[a],\n",
    "        # if a is not in dict, then set dict[a]=b and return\n",
    "        diameter_dict.setdefault(series_uid, []).append(\n",
    "            (annotationCenter_xyz, annotationDiameter_mm)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information of each nodule candidate from candidate file\n",
    "## use distance rather than abs\n",
    "def euclidean_distance(p1, p2):\n",
    "    distance = 0\n",
    "    for i in range(len(p1)):\n",
    "        distance += (p1[i]-p2[i])**2\n",
    "    return distance**0.5\n",
    "\n",
    "candidateInfo_list = []\n",
    "with open('./luna16/data/candidates.csv') as f:\n",
    "    for row in list(csv.reader(f))[1:]:\n",
    "        series_uid = row[0]\n",
    "        # check whether id is in the cache (in our subset file)\n",
    "        if series_uid not in presentOnDisk_set and requireOnDisk_bool:\n",
    "            continue # skip this one\n",
    "        # is nodule or not\n",
    "        isNodule_bool = bool(int(row[4]))\n",
    "        candidateCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "        # default diameter is 0\n",
    "        candidateDiameter_mm = 0.0\n",
    "        # dict.get(a, b): if a is in dict, then return dict[a],\n",
    "        # if a is not in dict, then return b\n",
    "        for annotation_tup in diameter_dict.get(series_uid, []):\n",
    "            annotationCenter_xyz, annotationDiameter_mm = annotation_tup\n",
    "            # distance measures how annotationcenter and candidatecenter apart\n",
    "            # If find one, then get annotationdiameter\n",
    "            # If not, then get the next annotation point in this same id\n",
    "            # If couldn't find in the end, then the diameter is 0\n",
    "            distance = euclidean_distance(annotationCenter_xyz, candidateCenter_xyz)\n",
    "            # my method\n",
    "            if distance > annotationDiameter_mm / 2:\n",
    "                continue\n",
    "            else:\n",
    "                candidateDiameter_mm = annotationDiameter_mm\n",
    "                break\n",
    "            # method in book\n",
    "#             for i in range(3):\n",
    "#                 delta_mm = abs(candidateCenter_xyz[i]-annotationCenter_xyz[i])\n",
    "#                 if delta_mm > annotationDiameter_mm / 4:\n",
    "#                     break\n",
    "#             else:\n",
    "#                 candidateDiameter_mm = annotationDiameter_mm\n",
    "#                 break\n",
    "            \n",
    "        # form the list of candidate info\n",
    "        candidateInfo_list.append(\n",
    "            CandidateInfoTuple(isNodule_bool,\n",
    "                               candidateDiameter_mm, \n",
    "                               series_uid, \n",
    "                               candidateCenter_xyz)\n",
    "        )\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the data with large diameter are at front\n",
    "candidateInfo_list.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imgdata\n",
    "def getct(series_uid):\n",
    "    mhd_path = glob.glob('./luna16/data/subset*/{}.mhd'.format(series_uid))[0]\n",
    "    # ct_mhd contains the info of dimension, convert matrix etc.\n",
    "    ct_mhd = sitk.ReadImage(mhd_path)\n",
    "    ct_np = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "    # set the min and max value based on HU units\n",
    "    # clip: set the value lower or higher than the thresholds to the thresholds\n",
    "    ct_np.clip( -1000, 1000, ct_np)\n",
    "    return (ct_mhd, ct_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x7f7f1cda9e90)\n",
      "  RTTI typeinfo:   itk::Image<short, 3u>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 897\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 870\n",
      "  UpdateMTime: 896\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  Spacing: [0.78125, 0.78125, 2.5]\n",
      "  Origin: [-191.2, -185.5, -359]\n",
      "  Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "0.78125 0 0\n",
      "0 0.78125 0\n",
      "0 0 2.5\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "1.28 0 0\n",
      "0 1.28 0\n",
      "0 0 0.4\n",
      "\n",
      "  Inverse Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x7f7f1c4e49f0)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, short>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 893\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0x7f7f0f1b2000\n",
      "      Container manages memory: true\n",
      "      Size: 34865152\n",
      "      Capacity: 34865152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct_mhd, ct_np = getct('1.3.6.1.4.1.14519.5.2.1.6279.6001.487268565754493433372433148666')\n",
    "print(ct_mhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 512, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrcTuple = namedtuple('IrcTuple', ['index', 'row', 'col'])\n",
    "XyzTuple = namedtuple('XyzTuple', ['x', 'y', 'z'])\n",
    "\n",
    "def irc2xyz(coord_irc, origin_xyz, vxSize_xyz, direction_a):\n",
    "    cri_a = np.array(coord_irc)[::-1]\n",
    "    origin_xyz = np.array(origin_xyz)\n",
    "    vxSize_xyz = np.array(vxSize_xyz)\n",
    "    # * is the multiplication of each value, @ is inner multiplication\n",
    "    coord_xyz = direction_a @ (cri_a * vxSize_xyz) + origin_xyz\n",
    "    # *coord_xyz: input all the parameters as tuple\n",
    "    # **coord_xyz: input all the parameters as dic\n",
    "    return XyzTuple(*coord_xyz)\n",
    "\n",
    "def xyz2irc(coord_xyz, origin_xyz, vxSize_xyz, direction_a):\n",
    "    coord_xyz = np.array(coord_xyz)\n",
    "    origin_xyz = np.array(origin_xyz)\n",
    "    vxSize_xyz = np.array(vxSize_xyz)\n",
    "    cri_a = (coord_xyz - origin_xyz) @ np.linalg.inv(direction_a) / vxSize_xyz\n",
    "    cri_a = np.round(cri_a)\n",
    "    # int doesn't do half adjusting\n",
    "    return IrcTuple(int(cri_a[2]), int(cri_a[1]), int(cri_a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRawCandidate(center_xyz, origin_xyz, vxSize_xyz, \n",
    "                    direction_a, width_irc, ct_np):\n",
    "    # first get (index, row, channel)\n",
    "    # the format of center_irc is: IrcTuple(index=80, row=254, col=400)\n",
    "    center_irc = xyz2irc(center_xyz, origin_xyz, vxSize_xyz, direction_a)\n",
    "    # get the index of centered candidate\n",
    "    slice_list = []\n",
    "    for axis, center_val in enumerate(center_irc):\n",
    "        start_ndx = int(round(center_val-width_irc[axis]/2))\n",
    "        end_ndx = int(start_ndx+width_irc[axis])\n",
    "        slice_list.append(slice(start_ndx, end_ndx))\n",
    "    # slice at each dimension to form centered candidate\n",
    "    ct_chunk = ct_np[tuple(slice_list)]\n",
    "    return (ct_chunk, center_irc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem(ndx):\n",
    "    candidateInfo_tup = candidateInfo_list[ndx]\n",
    "    width_irc = (32, 48, 48)\n",
    "    ct_mhd, ct_np = getct(candidateInfo_tup.series_uid)\n",
    "    origin_xyz = ct_mhd.GetOrigin()\n",
    "    vxSize_xyz = ct_mhd.GetSpacing()\n",
    "    direction_a = np.array(ct_mhd.GetDirection()).reshape(3,3)\n",
    "    candidate_a, center_irc = getRawCandidate(candidateInfo_tup.center_xyz,\n",
    "                                             origin_xyz,\n",
    "                                             vxSize_xyz,\n",
    "                                             direction_a,\n",
    "                                             width_irc, \n",
    "                                             ct_np)\n",
    "    # transform to tensor\n",
    "    candidate_t = t.from_numpy(candidate_a)\n",
    "    candidate_t = candidate_t.to(t.float32)\n",
    "    # add a new dimension called 'channel'\n",
    "    candidate_t = candidate_t.unsqueeze(0)\n",
    "    # now we should get labels\n",
    "    pos_t = t.tensor([not candidateInfo_tup.isNodule_bool,\n",
    "                     candidateInfo_tup.isNodule_bool],\n",
    "                     # this t.long change true to 1, false to 0\n",
    "                     dtype=t.long)\n",
    "    return (candidate_t, pos_t, \n",
    "            candidateInfo_tup.series_uid, \n",
    "            candidateInfo_tup.center_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want a 8:2 split\n",
    "val_stride = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(val_stride = 0,\n",
    "                 isValSet_bool = None,\n",
    "                 series_uid = None):\n",
    "    # create a copy, so that changing value in candidateInfo_part wouldn't \n",
    "    # change the value in candidateInfo_list\n",
    "    candidateInfo_list_part = candidateInfo_list.copy()\n",
    "    # if we want only part of the data with series_uid\n",
    "    if series_uid:\n",
    "        candidateInfo_list_part = [\n",
    "            x for x in candidateInfo_list_part if x.series_uid == series_uid\n",
    "        ]\n",
    "    # if we want to get validation set\n",
    "    if isValSet_bool:\n",
    "        # assert means if val_stride<=0, then assert an error with val_stride\n",
    "        assert val_stride>0, val_stride\n",
    "        candidateInfo_list_part = candidateInfo_list_part[::val_stride]\n",
    "        assert candidateInfo_list_part\n",
    "    elif val_stride>0:\n",
    "        # delete the validation data get the training data\n",
    "        del candidateInfo_list_part[::val_stride]\n",
    "        assert candidateInfo_list_part\n",
    "    return candidateInfo_list_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45550 11388\n"
     ]
    }
   ],
   "source": [
    "trainSet = get_train_val(val_stride, isValSet_bool=False)\n",
    "valSet = get_train_val(val_stride, isValSet_bool=True)\n",
    "print(len(trainSet), len(valSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[-852., -887., -893.,  ..., -830., -846., -871.],\n",
      "          [-838., -877., -896.,  ..., -849., -868., -863.],\n",
      "          [-864., -874., -877.,  ..., -837., -854., -844.],\n",
      "          ...,\n",
      "          [  49.,   46.,   48.,  ...,  342.,  211.,  121.],\n",
      "          [  58.,   55.,   54.,  ...,   84.,   51.,   49.],\n",
      "          [  27.,   22.,   31.,  ...,   63.,   68.,   65.]],\n",
      "\n",
      "         [[-367., -596., -747.,  ..., -779., -666., -643.],\n",
      "          [-392., -522., -701.,  ..., -751., -616., -600.],\n",
      "          [-472., -524., -668.,  ..., -714., -586., -597.],\n",
      "          ...,\n",
      "          [  52.,   39.,   40.,  ...,  491.,  292.,  126.],\n",
      "          [  54.,   48.,   45.,  ...,  118.,   78.,   32.],\n",
      "          [  49.,   35.,   31.,  ...,   26.,   46.,   53.]],\n",
      "\n",
      "         [[-534., -419., -245.,  ..., -557., -374., -445.],\n",
      "          [-496., -342., -183.,  ..., -571., -389., -456.],\n",
      "          [-502., -282., -149.,  ..., -605., -410., -452.],\n",
      "          ...,\n",
      "          [  62.,   70.,   50.,  ...,  345.,  185.,  100.],\n",
      "          [  63.,   70.,   59.,  ...,  122.,   83.,   68.],\n",
      "          [  50.,   46.,   59.,  ...,   61.,   55.,   48.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-900., -911., -904.,  ..., -905., -899., -896.],\n",
      "          [-901., -920., -922.,  ..., -863., -913., -916.],\n",
      "          [-890., -937., -938.,  ..., -864., -898., -901.],\n",
      "          ...,\n",
      "          [ 643.,  664.,  690.,  ...,   34.,   33.,   41.],\n",
      "          [ 625.,  690.,  772.,  ...,   19.,   17.,  -15.],\n",
      "          [ 417.,  459.,  502.,  ...,   -2.,    3.,   16.]],\n",
      "\n",
      "         [[-874., -880., -885.,  ..., -820., -879., -883.],\n",
      "          [-864., -853., -875.,  ..., -778., -879., -886.],\n",
      "          [-872., -867., -876.,  ..., -815., -846., -875.],\n",
      "          ...,\n",
      "          [ 713.,  765.,  726.,  ...,   13.,   12.,   22.],\n",
      "          [ 499.,  517.,  530.,  ...,   -1.,   32.,   18.],\n",
      "          [ 306.,  298.,  267.,  ...,   13.,   46.,   45.]],\n",
      "\n",
      "         [[-905., -919., -910.,  ..., -632., -741., -794.],\n",
      "          [-904., -919., -925.,  ..., -464., -560., -658.],\n",
      "          [-897., -893., -906.,  ..., -491., -477., -551.],\n",
      "          ...,\n",
      "          [ 533.,  565.,  479.,  ...,    9.,   19.,   40.],\n",
      "          [ 305.,  328.,  357.,  ...,   42.,   40.,   42.],\n",
      "          [ 223.,  219.,  261.,  ...,   39.,   48.,   35.]]]]), tensor([0, 1]), '1.3.6.1.4.1.14519.5.2.1.6279.6001.511347030803753100045216493273', (59.1136546856, 82.9816128068, -213.127954744))\n"
     ]
    }
   ],
   "source": [
    "print(getitem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# subclass Dataset\n",
    "class LunaDataset(Dataset):\n",
    "    def __init__(self, val_stride=0, isValSet_bool=None, series_uid=None):\n",
    "        self.candidateInfo_list = candidateInfo_list.copy()\n",
    "        if series_uid:\n",
    "            self.candidateInfo_list = [\n",
    "                x for x in self.candidateInfo_list if x.series_uid==series_uid\n",
    "            ]\n",
    "        if isValSet_bool:\n",
    "            assert val_stride>0, val_stride\n",
    "            self.candidateInfo_list = self.candidateInfo_list[::val_stride]\n",
    "            assert self.candidateInfo_list\n",
    "        elif val_stride>0:\n",
    "            # delete the validation data get the training data\n",
    "            del self.candidateInfo_list[::val_stride]\n",
    "            assert self.candidateInfo_list\n",
    "            \n",
    "    # the function we need to define\n",
    "    def __len__(self):\n",
    "        return len(self.candidateInfo_list)\n",
    "    \n",
    "    # the function we need to define\n",
    "    def __getitem__(self, ndx):\n",
    "        candidateInfo_tup = self.candidateInfo_list[ndx]\n",
    "        width_irc = (32, 48, 48)\n",
    "        ct_mhd, ct_np = getct(candidateInfo_tup.series_uid)\n",
    "        origin_xyz = ct_mhd.GetOrigin()\n",
    "        vxSize_xyz = ct_mhd.GetSpacing()\n",
    "        direction_a = np.array(ct_mhd.GetDirection()).reshape(3,3)\n",
    "        candidate_a, center_irc = getRawCandidate(candidateInfo_tup.center_xyz,\n",
    "                                                 origin_xyz,\n",
    "                                                 vxSize_xyz,\n",
    "                                                 direction_a,\n",
    "                                                 width_irc, \n",
    "                                                 ct_np)\n",
    "        # transform to tensor\n",
    "        candidate_t = t.from_numpy(candidate_a)\n",
    "        candidate_t = candidate_t.to(t.float32)\n",
    "        # add a new dimension called 'channel'\n",
    "        candidate_t = candidate_t.unsqueeze(0)\n",
    "        print(candidate_t.shape)\n",
    "        # now we should get labels\n",
    "        pos_t = t.tensor([not candidateInfo_tup.isNodule_bool,\n",
    "                         candidateInfo_tup.isNodule_bool],\n",
    "                         # this t.long change true to 1, false to 0\n",
    "                         dtype=t.long)\n",
    "        return (candidate_t, pos_t, \n",
    "                candidateInfo_tup.series_uid, \n",
    "                candidateInfo_tup.center_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 48, 48])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[[-852., -887., -893.,  ..., -830., -846., -871.],\n",
       "           [-838., -877., -896.,  ..., -849., -868., -863.],\n",
       "           [-864., -874., -877.,  ..., -837., -854., -844.],\n",
       "           ...,\n",
       "           [  49.,   46.,   48.,  ...,  342.,  211.,  121.],\n",
       "           [  58.,   55.,   54.,  ...,   84.,   51.,   49.],\n",
       "           [  27.,   22.,   31.,  ...,   63.,   68.,   65.]],\n",
       " \n",
       "          [[-367., -596., -747.,  ..., -779., -666., -643.],\n",
       "           [-392., -522., -701.,  ..., -751., -616., -600.],\n",
       "           [-472., -524., -668.,  ..., -714., -586., -597.],\n",
       "           ...,\n",
       "           [  52.,   39.,   40.,  ...,  491.,  292.,  126.],\n",
       "           [  54.,   48.,   45.,  ...,  118.,   78.,   32.],\n",
       "           [  49.,   35.,   31.,  ...,   26.,   46.,   53.]],\n",
       " \n",
       "          [[-534., -419., -245.,  ..., -557., -374., -445.],\n",
       "           [-496., -342., -183.,  ..., -571., -389., -456.],\n",
       "           [-502., -282., -149.,  ..., -605., -410., -452.],\n",
       "           ...,\n",
       "           [  62.,   70.,   50.,  ...,  345.,  185.,  100.],\n",
       "           [  63.,   70.,   59.,  ...,  122.,   83.,   68.],\n",
       "           [  50.,   46.,   59.,  ...,   61.,   55.,   48.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-900., -911., -904.,  ..., -905., -899., -896.],\n",
       "           [-901., -920., -922.,  ..., -863., -913., -916.],\n",
       "           [-890., -937., -938.,  ..., -864., -898., -901.],\n",
       "           ...,\n",
       "           [ 643.,  664.,  690.,  ...,   34.,   33.,   41.],\n",
       "           [ 625.,  690.,  772.,  ...,   19.,   17.,  -15.],\n",
       "           [ 417.,  459.,  502.,  ...,   -2.,    3.,   16.]],\n",
       " \n",
       "          [[-874., -880., -885.,  ..., -820., -879., -883.],\n",
       "           [-864., -853., -875.,  ..., -778., -879., -886.],\n",
       "           [-872., -867., -876.,  ..., -815., -846., -875.],\n",
       "           ...,\n",
       "           [ 713.,  765.,  726.,  ...,   13.,   12.,   22.],\n",
       "           [ 499.,  517.,  530.,  ...,   -1.,   32.,   18.],\n",
       "           [ 306.,  298.,  267.,  ...,   13.,   46.,   45.]],\n",
       " \n",
       "          [[-905., -919., -910.,  ..., -632., -741., -794.],\n",
       "           [-904., -919., -925.,  ..., -464., -560., -658.],\n",
       "           [-897., -893., -906.,  ..., -491., -477., -551.],\n",
       "           ...,\n",
       "           [ 533.,  565.,  479.,  ...,    9.,   19.,   40.],\n",
       "           [ 305.,  328.,  357.,  ...,   42.,   40.,   42.],\n",
       "           [ 223.,  219.,  261.,  ...,   39.,   48.,   35.]]]]),\n",
       " tensor([0, 1]),\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.511347030803753100045216493273',\n",
       " (59.1136546856, 82.9816128068, -213.127954744))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get the same result\n",
    "LunaDataset()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store it in DataLoader\n",
    "trainSet = LunaDataset(val_stride, isValSet_bool=False)\n",
    "batch_size = 256\n",
    "trainLoader = DataLoader(trainSet, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45550"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainLoader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model block\n",
    "class LunaBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=in_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=3,\n",
    "                              padding=1,\n",
    "                              bias=True)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv3d(in_channels=out_channels,\n",
    "                              out_channels=out_channels,\n",
    "                              kernel_size=3,\n",
    "                              padding=1,\n",
    "                              bias=True)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool3d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, inputbatch):\n",
    "        out = self.conv1(inputbatch)\n",
    "        out = self.relu1(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.relu2(out)\n",
    "        out = self.maxpool(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model formed by blocks\n",
    "class LunaModel(nn.Module):\n",
    "    def __init__(self, in_channels=1, conv_channels=8):\n",
    "        super().__init__()\n",
    "        self.tail_batchnorm = nn.BatchNorm3d(num_features=in_channels)\n",
    "        \n",
    "        self.block1 = LunaBlock(in_channels, conv_channels)\n",
    "        self.block2 = LunaBlock(conv_channels, conv_channels*2)\n",
    "        self.block3 = LunaBlock(conv_channels*2, conv_channels*4)\n",
    "        self.block4 = LunaBlock(conv_channels*4, conv_channels*8)\n",
    "        \n",
    "        # after 4 maxpool, 32*48*48 becomes 2*3*3\n",
    "        self.head_linear = nn.Linear(1152, 2)\n",
    "        self.head_softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, input_batch):\n",
    "        out = self.tail_batchnorm(input_batch)\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        # convert to vector\n",
    "        out = out.view(out.shape[0], -1)\n",
    "        out = self.head_linear(out)\n",
    "        return out, self.head_softmax(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training loop\n",
    "def trainloop(model, trainloader, nepoches, optimizer, lossfn):\n",
    "    for epoch in range(1, nepoches+1):\n",
    "        start_time = time.time\n",
    "        losstrain = 0\n",
    "        for data, labels, uid, xyz in trainloader:\n",
    "            # aux is another element in the output tuple\n",
    "            out, aux = model(data)\n",
    "            # cross entropy don't recognize one-hot.\n",
    "            # change labels to one vector with labels\n",
    "            labels = t.max(labels, 1)[1]\n",
    "            loss = lossfn(out, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            losstrain += loss.item()\n",
    "        \n",
    "        if epoch % 4 == 0:\n",
    "            end_time = time.time()\n",
    "            used_time = end_time-start_time\n",
    "            print('epoch {}, training loss {}, time used {}'.format(\n",
    "                epoch, loss_train/len(trainloader), used_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 0, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n",
      "torch.Size([1, 32, 48, 48])\n"
     ]
    }
   ],
   "source": [
    "model = LunaModel()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-2)\n",
    "lossfn = nn.CrossEntropyLoss()\n",
    "\n",
    "trainloop(model, trainLoader, 8, optimizer, lossfn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 1\n",
    "~a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 1\n",
      "1 2\n",
      "2 4\n",
      "3 3\n",
      "4 1\n"
     ]
    }
   ],
   "source": [
    "for i, j in enumerate(a):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 4, 3, 1]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

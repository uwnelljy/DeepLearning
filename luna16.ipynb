{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 1 and 2\n",
      "3\n",
      "3\n",
      "add 3 and 4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# What does lru_cache do?\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(1)\n",
    "def addxy(x, y):\n",
    "    print('add {} and {}'.format(x, y))\n",
    "    return x+y\n",
    "\n",
    "print(addxy(1, 2))\n",
    "print(addxy(1, 2))\n",
    "print(addxy(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "CandidateInfoTuple = namedtuple(\n",
    "'CandidateInfoTuple', # this namedtuple's name\n",
    "'isNodule_bool, diameter_mm, series_uid, center_xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name of .mhd file I downloaded and store these information in cache\n",
    "# no return, just store\n",
    "requireOnDisk_bool = True\n",
    "@lru_cache(1)\n",
    "def getCandidateInfoList(requireOnDisk_bool=requireOnDisk_bool):\n",
    "    # a default parameter of this function\n",
    "    mhd_list = glob.glob('./luna16/data/subset*/*.mhd')\n",
    "    # mhd_list is a list of file paths, like '/subset7/534991.mhd'\n",
    "    # os.path.split(p) returns a list of os.path and p, [path, p]\n",
    "    # -1 we get p, and :-4 we drop .mhd and get only the name\n",
    "    presentOnDisk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "    return(presentOnDisk_set)\n",
    "\n",
    "presentOnDisk_set = getCandidateInfoList(requireOnDisk_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about diameter for each id\n",
    "diameter_dict = {}\n",
    "with open('./luna16/data/annotations.csv') as f:\n",
    "    # csv.reader: read f in csv version, so row is a list of each element\n",
    "    # 1: because the first row is header\n",
    "    for row in list(csv.reader(f))[1:]:\n",
    "        series_uid = row[0]\n",
    "        annotationCenter_xyz = tuple(float(x) for x in row[1:4])\n",
    "        annotationDiameter_mm = float(row[4])\n",
    "        # dict.setdefault(a, b): if a is in dict, then return dict[a],\n",
    "        # if a is not in dict, then set dict[a]=b and return\n",
    "        diameter_dict.setdefault(series_uid, []).append(\n",
    "            (annotationCenter_xyz, annotationDiameter_mm)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information of each nodule candidate from candidate file\n",
    "## use distance rather than abs\n",
    "def euclidean_distance(p1, p2):\n",
    "    distance = 0\n",
    "    for i in range(len(p1)):\n",
    "        distance += (p1[i]-p2[i])**2\n",
    "    return distance**0.5\n",
    "\n",
    "candidateInfo_list = []\n",
    "with open('./luna16/data/candidates.csv') as f:\n",
    "    for row in list(csv.reader(f))[1:]:\n",
    "        series_uid = row[0]\n",
    "        # check whether id is in the cache (in our subset file)\n",
    "        if series_uid not in presentOnDisk_set and requireOnDisk_bool:\n",
    "            continue # skip this one\n",
    "        # is nodule or not\n",
    "        isNodule_bool = bool(int(row[4]))\n",
    "        candidateCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "        # default diameter is 0\n",
    "        candidateDiameter_mm = 0.0\n",
    "        # dict.get(a, b): if a is in dict, then return dict[a],\n",
    "        # if a is not in dict, then return b\n",
    "        for annotation_tup in diameter_dict.get(series_uid, []):\n",
    "            annotationCenter_xyz, annotationDiameter_mm = annotation_tup\n",
    "            # distance measures how annotationcenter and candidatecenter apart\n",
    "            # If find one, then get annotationdiameter\n",
    "            # If not, then get the next annotation point in this same id\n",
    "            # If couldn't find in the end, then the diameter is 0\n",
    "            distance = euclidean_distance(annotationCenter_xyz, candidateCenter_xyz)\n",
    "            # my method\n",
    "            if distance > annotationDiameter_mm / 2:\n",
    "                continue\n",
    "            else:\n",
    "                candidateDiameter_mm = annotationDiameter_mm\n",
    "                break\n",
    "            # method in book\n",
    "#             for i in range(3):\n",
    "#                 delta_mm = abs(candidateCenter_xyz[i]-annotationCenter_xyz[i])\n",
    "#                 if delta_mm > annotationDiameter_mm / 4:\n",
    "#                     break\n",
    "#             else:\n",
    "#                 candidateDiameter_mm = annotationDiameter_mm\n",
    "#                 break\n",
    "            \n",
    "        # form the list of candidate info\n",
    "        candidateInfo_list.append(\n",
    "            CandidateInfoTuple(isNodule_bool,\n",
    "                               candidateDiameter_mm, \n",
    "                               series_uid, \n",
    "                               candidateCenter_xyz)\n",
    "        )\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the data with large diameter are at front\n",
    "candidateInfo_list.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imgdata\n",
    "def getct(series_uid):\n",
    "    mhd_path = glob.glob('./luna16/data/subset*/{}.mhd'.format(series_uid))[0]\n",
    "    # ct_mhd contains the info of dimension, convert matrix etc.\n",
    "    ct_mhd = sitk.ReadImage(mhd_path)\n",
    "    ct_np = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "    # set the min and max value based on HU units\n",
    "    # clip: set the value lower or higher than the thresholds to the thresholds\n",
    "    ct_np.clip( -1000, 1000, ct_np)\n",
    "    return (ct_mhd, ct_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x7f912cce56c0)\n",
      "  RTTI typeinfo:   itk::Image<short, 3u>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 3493\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 3466\n",
      "  UpdateMTime: 3492\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  Spacing: [0.78125, 0.78125, 2.5]\n",
      "  Origin: [-191.2, -185.5, -359]\n",
      "  Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "0.78125 0 0\n",
      "0 0.78125 0\n",
      "0 0 2.5\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "1.28 0 0\n",
      "0 1.28 0\n",
      "0 0 0.4\n",
      "\n",
      "  Inverse Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x7f9110462f50)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, short>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 3489\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0x7f909cdb7000\n",
      "      Container manages memory: true\n",
      "      Size: 34865152\n",
      "      Capacity: 34865152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(ct_mhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 512, 512)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrcTuple = namedtuple('IrcTuple', ['index', 'row', 'col'])\n",
    "XyzTuple = namedtuple('XyzTuple', ['x', 'y', 'z'])\n",
    "\n",
    "def irc2xyz(coord_irc, origin_xyz, vxSize_xyz, direction_a):\n",
    "    cri_a = np.array(coord_irc)[::-1]\n",
    "    origin_xyz = np.array(origin_xyz)\n",
    "    vxSize_xyz = np.array(vxSize_xyz)\n",
    "    # * is the multiplication of each value, @ is inner multiplication\n",
    "    coord_xyz = direction_a @ (cri_a * vxSize_xyz) + origin_xyz\n",
    "    # *coord_xyz: input all the parameters as tuple\n",
    "    # **coord_xyz: input all the parameters as dic\n",
    "    return XyzTuple(*coord_xyz)\n",
    "\n",
    "def xyz2irc(coord_xyz, origin_xyz, vxSize_xyz, direction_a):\n",
    "    coord_xyz = np.array(coord_xyz)\n",
    "    origin_xyz = np.array(origin_xyz)\n",
    "    vxSize_xyz = np.array(vxSize_xyz)\n",
    "    cri_a = (coord_xyz - origin_xyz) @ np.linalg.inv(direction_a) / vxSize_xyz\n",
    "    cri_a = np.round(cri_a)\n",
    "    # int doesn't do half adjusting\n",
    "    return IrcTuple(int(cri_a[2]), int(cri_a[1]), int(cri_a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRawCandidate(center_xyz, origin_xyz, vxSize_xyz, \n",
    "                    direction_a, width_irc, ct_np):\n",
    "    # first get (index, row, channel)\n",
    "    # the format of center_irc is: IrcTuple(index=80, row=254, col=400)\n",
    "    center_irc = xyz2irc(center_xyz, origin_xyz, vxSize_xyz, direction_a)\n",
    "    # get the index of centered candidate\n",
    "    slice_list = []\n",
    "    for axis, center_val in enumerate(center_irc):\n",
    "        start_ndx = int(round(center_val-width_irc[axis]/2))\n",
    "        end_ndx = int(start_ndx+width_irc[axis])\n",
    "        slice_list.append(slice(start_ndx, end_ndx))\n",
    "    # slice at each dimension to form centered candidate\n",
    "    ct_chunk = ct_np[tuple(slice_list)]\n",
    "    return (ct_chunk, center_irc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem(ndx):\n",
    "    candidateInfo_tup = candidateInfo_list[ndx]\n",
    "    width_irc = (32, 48, 48)\n",
    "    ct_mhd, ct_np = getct(candidateInfo_tup.series_uid)\n",
    "    origin_xyz = ct_mhd.GetOrigin()\n",
    "    vxSize_xyz = ct_mhd.GetSpacing()\n",
    "    direction_a = np.array(ct_mhd.GetDirection()).reshape(3,3)\n",
    "    candidate_a, center_irc = getRawCandidate(candidateInfo_tup.center_xyz,\n",
    "                                             origin_xyz,\n",
    "                                             vxSize_xyz,\n",
    "                                             direction_a,\n",
    "                                             width_irc, \n",
    "                                             ct_np)\n",
    "    # transform to tensor\n",
    "    candidate_t = t.from_numpy(candidate_a)\n",
    "    candidate_t = candidate_t.to(t.float32)\n",
    "    # add a new dimension called 'channel'\n",
    "    candidate_t = candidate_t.unsqueeze(0)\n",
    "    # now we should get labels\n",
    "    pos_t = t.tensor([not candidateInfo_tup.isNodule_bool,\n",
    "                     candidateInfo_tup.isNodule_bool],\n",
    "                     # this t.long change true to 1, false to 0\n",
    "                    dtype=t.long)\n",
    "    return (candidate_t, pos_t, \n",
    "            candidateInfo_tup.series_uid, \n",
    "            candidateInfo_tup.center_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(val_stride = 0,\n",
    "                 isValSet_bool = None,\n",
    "                 series_uid = None):\n",
    "    # create a copy, so that changing value in candidateInfo_part wouldn't \n",
    "    # change the value in candidateInfo_list\n",
    "    candidateInfo_list_part = candidateInfo_list.copy()\n",
    "    # if we want only part of the data with series_uid\n",
    "    if series_uid:\n",
    "        candidateInfo_list_part = [\n",
    "            x for x in candidateInfo_list_part if x.series_uid == series_uid\n",
    "        ]\n",
    "    # if we want to get validation set\n",
    "    if isValSet_bool:\n",
    "        # assert means if val_stride<=0, then assert an error with val_stride\n",
    "        assert val_stride>0, val_stride\n",
    "        candidateInfo_list_part = candidateInfo_list_part[::val_stride]\n",
    "        assert candidateInfo_list_part\n",
    "    elif val_stride>0:\n",
    "        # delete the validation data get the training data\n",
    "        del candidateInfo_list_part[::val_stride]\n",
    "        assert candidateInfo_list_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

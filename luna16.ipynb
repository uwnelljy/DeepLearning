{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add 1 and 2\n",
      "3\n",
      "3\n",
      "add 3 and 4\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "# What does lru_cache do?\n",
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache(1)\n",
    "def addxy(x, y):\n",
    "    print('add {} and {}'.format(x, y))\n",
    "    return x+y\n",
    "\n",
    "print(addxy(1, 2))\n",
    "print(addxy(1, 2))\n",
    "print(addxy(3, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from collections import namedtuple\n",
    "import os\n",
    "import csv\n",
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import torch as t\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CandidateInfoTuple = namedtuple(\n",
    "'CandidateInfoTuple', # this namedtuple's name\n",
    "'isNodule_bool, diameter_mm, series_uid, center_xyz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the name of .mhd file I downloaded and store these information in cache\n",
    "# no return, just store\n",
    "requireOnDisk_bool = True\n",
    "@lru_cache(1)\n",
    "def getCandidateInfoList(requireOnDisk_bool=requireOnDisk_bool):\n",
    "    # a default parameter of this function\n",
    "    mhd_list = glob.glob('./luna16/data/subset*/*.mhd')\n",
    "    # mhd_list is a list of file paths, like '/subset7/534991.mhd'\n",
    "    # os.path.split(p) returns a list of os.path and p, [path, p]\n",
    "    # -1 we get p, and :-4 we drop .mhd and get only the name\n",
    "    presentOnDisk_set = {os.path.split(p)[-1][:-4] for p in mhd_list}\n",
    "    return(presentOnDisk_set)\n",
    "\n",
    "presentOnDisk_set = getCandidateInfoList(requireOnDisk_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information about diameter for each id\n",
    "diameter_dict = {}\n",
    "with open('./luna16/data/annotations.csv') as f:\n",
    "    # csv.reader: read f in csv version, so row is a list of each element\n",
    "    # 1: because the first row is header\n",
    "    for row in list(csv.reader(f))[1:]:\n",
    "        series_uid = row[0]\n",
    "        annotationCenter_xyz = tuple(float(x) for x in row[1:4])\n",
    "        annotationDiameter_mm = float(row[4])\n",
    "        # dict.setdefault(a, b): if a is in dict, then return dict[a],\n",
    "        # if a is not in dict, then set dict[a]=b and return\n",
    "        diameter_dict.setdefault(series_uid, []).append(\n",
    "            (annotationCenter_xyz, annotationDiameter_mm)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get information of each nodule candidate from candidate file\n",
    "## use distance rather than abs\n",
    "def euclidean_distance(p1, p2):\n",
    "    distance = 0\n",
    "    for i in range(len(p1)):\n",
    "        distance += (p1[i]-p2[i])**2\n",
    "    return distance**0.5\n",
    "\n",
    "candidateInfo_list = []\n",
    "with open('./luna16/data/candidates.csv') as f:\n",
    "    for row in list(csv.reader(f))[1:]:\n",
    "        series_uid = row[0]\n",
    "        # check whether id is in the cache (in our subset file)\n",
    "        if series_uid not in presentOnDisk_set and requireOnDisk_bool:\n",
    "            continue # skip this one\n",
    "        # is nodule or not\n",
    "        isNodule_bool = bool(int(row[4]))\n",
    "        candidateCenter_xyz = tuple([float(x) for x in row[1:4]])\n",
    "        # default diameter is 0\n",
    "        candidateDiameter_mm = 0.0\n",
    "        # dict.get(a, b): if a is in dict, then return dict[a],\n",
    "        # if a is not in dict, then return b\n",
    "        for annotation_tup in diameter_dict.get(series_uid, []):\n",
    "            annotationCenter_xyz, annotationDiameter_mm = annotation_tup\n",
    "            # distance measures how annotationcenter and candidatecenter apart\n",
    "            # If find one, then get annotationdiameter\n",
    "            # If not, then get the next annotation point in this same id\n",
    "            # If couldn't find in the end, then the diameter is 0\n",
    "            distance = euclidean_distance(annotationCenter_xyz, candidateCenter_xyz)\n",
    "            # my method\n",
    "            if distance > annotationDiameter_mm / 2:\n",
    "                continue\n",
    "            else:\n",
    "                candidateDiameter_mm = annotationDiameter_mm\n",
    "                break\n",
    "            # method in book\n",
    "#             for i in range(3):\n",
    "#                 delta_mm = abs(candidateCenter_xyz[i]-annotationCenter_xyz[i])\n",
    "#                 if delta_mm > annotationDiameter_mm / 4:\n",
    "#                     break\n",
    "#             else:\n",
    "#                 candidateDiameter_mm = annotationDiameter_mm\n",
    "#                 break\n",
    "            \n",
    "        # form the list of candidate info\n",
    "        candidateInfo_list.append(\n",
    "            CandidateInfoTuple(isNodule_bool,\n",
    "                               candidateDiameter_mm, \n",
    "                               series_uid, \n",
    "                               candidateCenter_xyz)\n",
    "        )\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all the data with large diameter are at front\n",
    "candidateInfo_list.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get imgdata\n",
    "def getct(series_uid):\n",
    "    mhd_path = glob.glob('./luna16/data/subset*/{}.mhd'.format(series_uid))[0]\n",
    "    # ct_mhd contains the info of dimension, convert matrix etc.\n",
    "    ct_mhd = sitk.ReadImage(mhd_path)\n",
    "    ct_np = np.array(sitk.GetArrayFromImage(ct_mhd), dtype=np.float32)\n",
    "    # set the min and max value based on HU units\n",
    "    # clip: set the value lower or higher than the thresholds to the thresholds\n",
    "    ct_np.clip( -1000, 1000, ct_np)\n",
    "    return (ct_mhd, ct_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image (0x7ff322124830)\n",
      "  RTTI typeinfo:   itk::Image<short, 3u>\n",
      "  Reference Count: 1\n",
      "  Modified Time: 897\n",
      "  Debug: Off\n",
      "  Object Name: \n",
      "  Observers: \n",
      "    none\n",
      "  Source: (none)\n",
      "  Source output name: (none)\n",
      "  Release Data: Off\n",
      "  Data Released: False\n",
      "  Global Release Data: Off\n",
      "  PipelineMTime: 870\n",
      "  UpdateMTime: 896\n",
      "  RealTimeStamp: 0 seconds \n",
      "  LargestPossibleRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  BufferedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  RequestedRegion: \n",
      "    Dimension: 3\n",
      "    Index: [0, 0, 0]\n",
      "    Size: [512, 512, 133]\n",
      "  Spacing: [0.78125, 0.78125, 2.5]\n",
      "  Origin: [-191.2, -185.5, -359]\n",
      "  Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  IndexToPointMatrix: \n",
      "0.78125 0 0\n",
      "0 0.78125 0\n",
      "0 0 2.5\n",
      "\n",
      "  PointToIndexMatrix: \n",
      "1.28 0 0\n",
      "0 1.28 0\n",
      "0 0 0.4\n",
      "\n",
      "  Inverse Direction: \n",
      "1 0 0\n",
      "0 1 0\n",
      "0 0 1\n",
      "\n",
      "  PixelContainer: \n",
      "    ImportImageContainer (0x7ff322137080)\n",
      "      RTTI typeinfo:   itk::ImportImageContainer<unsigned long, short>\n",
      "      Reference Count: 1\n",
      "      Modified Time: 893\n",
      "      Debug: Off\n",
      "      Object Name: \n",
      "      Observers: \n",
      "        none\n",
      "      Pointer: 0x7ff316e92000\n",
      "      Container manages memory: true\n",
      "      Size: 34865152\n",
      "      Capacity: 34865152\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ct_mhd, ct_np = getct('1.3.6.1.4.1.14519.5.2.1.6279.6001.487268565754493433372433148666')\n",
    "print(ct_mhd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 512, 512)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IrcTuple = namedtuple('IrcTuple', ['index', 'row', 'col'])\n",
    "XyzTuple = namedtuple('XyzTuple', ['x', 'y', 'z'])\n",
    "\n",
    "def irc2xyz(coord_irc, origin_xyz, vxSize_xyz, direction_a):\n",
    "    cri_a = np.array(coord_irc)[::-1]\n",
    "    origin_xyz = np.array(origin_xyz)\n",
    "    vxSize_xyz = np.array(vxSize_xyz)\n",
    "    # * is the multiplication of each value, @ is inner multiplication\n",
    "    coord_xyz = direction_a @ (cri_a * vxSize_xyz) + origin_xyz\n",
    "    # *coord_xyz: input all the parameters as tuple\n",
    "    # **coord_xyz: input all the parameters as dic\n",
    "    return XyzTuple(*coord_xyz)\n",
    "\n",
    "def xyz2irc(coord_xyz, origin_xyz, vxSize_xyz, direction_a):\n",
    "    coord_xyz = np.array(coord_xyz)\n",
    "    origin_xyz = np.array(origin_xyz)\n",
    "    vxSize_xyz = np.array(vxSize_xyz)\n",
    "    cri_a = (coord_xyz - origin_xyz) @ np.linalg.inv(direction_a) / vxSize_xyz\n",
    "    cri_a = np.round(cri_a)\n",
    "    # int doesn't do half adjusting\n",
    "    return IrcTuple(int(cri_a[2]), int(cri_a[1]), int(cri_a[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRawCandidate(center_xyz, origin_xyz, vxSize_xyz, \n",
    "                    direction_a, width_irc, ct_np):\n",
    "    # first get (index, row, channel)\n",
    "    # the format of center_irc is: IrcTuple(index=80, row=254, col=400)\n",
    "    center_irc = xyz2irc(center_xyz, origin_xyz, vxSize_xyz, direction_a)\n",
    "    # get the index of centered candidate\n",
    "    slice_list = []\n",
    "    for axis, center_val in enumerate(center_irc):\n",
    "        start_ndx = int(round(center_val-width_irc[axis]/2))\n",
    "        end_ndx = int(start_ndx+width_irc[axis])\n",
    "        slice_list.append(slice(start_ndx, end_ndx))\n",
    "    # slice at each dimension to form centered candidate\n",
    "    ct_chunk = ct_np[tuple(slice_list)]\n",
    "    return (ct_chunk, center_irc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getitem(ndx):\n",
    "    candidateInfo_tup = candidateInfo_list[ndx]\n",
    "    width_irc = (32, 48, 48)\n",
    "    ct_mhd, ct_np = getct(candidateInfo_tup.series_uid)\n",
    "    origin_xyz = ct_mhd.GetOrigin()\n",
    "    vxSize_xyz = ct_mhd.GetSpacing()\n",
    "    direction_a = np.array(ct_mhd.GetDirection()).reshape(3,3)\n",
    "    candidate_a, center_irc = getRawCandidate(candidateInfo_tup.center_xyz,\n",
    "                                             origin_xyz,\n",
    "                                             vxSize_xyz,\n",
    "                                             direction_a,\n",
    "                                             width_irc, \n",
    "                                             ct_np)\n",
    "    # transform to tensor\n",
    "    candidate_t = t.from_numpy(candidate_a)\n",
    "    candidate_t = candidate_t.to(t.float32)\n",
    "    # add a new dimension called 'channel'\n",
    "    candidate_t = candidate_t.unsqueeze(0)\n",
    "    # now we should get labels\n",
    "    pos_t = t.tensor([not candidateInfo_tup.isNodule_bool,\n",
    "                     candidateInfo_tup.isNodule_bool],\n",
    "                     # this t.long change true to 1, false to 0\n",
    "                     dtype=t.long)\n",
    "    return (candidate_t, pos_t, \n",
    "            candidateInfo_tup.series_uid, \n",
    "            candidateInfo_tup.center_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we want a 8:2 split\n",
    "val_stride = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_val(val_stride = 0,\n",
    "                 isValSet_bool = None,\n",
    "                 series_uid = None):\n",
    "    # create a copy, so that changing value in candidateInfo_part wouldn't \n",
    "    # change the value in candidateInfo_list\n",
    "    candidateInfo_list_part = candidateInfo_list.copy()\n",
    "    # if we want only part of the data with series_uid\n",
    "    if series_uid:\n",
    "        candidateInfo_list_part = [\n",
    "            x for x in candidateInfo_list_part if x.series_uid == series_uid\n",
    "        ]\n",
    "    # if we want to get validation set\n",
    "    if isValSet_bool:\n",
    "        # assert means if val_stride<=0, then assert an error with val_stride\n",
    "        assert val_stride>0, val_stride\n",
    "        candidateInfo_list_part = candidateInfo_list_part[::val_stride]\n",
    "        assert candidateInfo_list_part\n",
    "    elif val_stride>0:\n",
    "        # delete the validation data get the training data\n",
    "        del candidateInfo_list_part[::val_stride]\n",
    "        assert candidateInfo_list_part\n",
    "    return candidateInfo_list_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178530 44633\n"
     ]
    }
   ],
   "source": [
    "trainSet = get_train_val(val_stride, isValSet_bool=False)\n",
    "valSet = get_train_val(val_stride, isValSet_bool=True)\n",
    "print(len(trainSet), len(valSet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[[  41.,   65.,   69.,  ..., -896., -900., -898.],\n",
      "          [  67.,   70.,   62.,  ..., -889., -899., -916.],\n",
      "          [  65.,   86.,   88.,  ..., -865., -875., -903.],\n",
      "          ...,\n",
      "          [-803., -812., -839.,  ..., -843., -847., -839.],\n",
      "          [-840., -842., -848.,  ..., -824., -830., -817.],\n",
      "          [-831., -839., -849.,  ..., -818., -817., -809.]],\n",
      "\n",
      "         [[  48.,   42.,   22.,  ..., -880., -879., -874.],\n",
      "          [  61.,   47.,   12.,  ..., -899., -885., -882.],\n",
      "          [  42.,   39.,   -1.,  ..., -909., -909., -887.],\n",
      "          ...,\n",
      "          [-853., -867., -872.,  ..., -859., -855., -886.],\n",
      "          [-879., -890., -871.,  ..., -867., -862., -880.],\n",
      "          [-880., -874., -842.,  ..., -882., -866., -860.]],\n",
      "\n",
      "         [[ -30., -109., -195.,  ..., -874., -883., -871.],\n",
      "          [ -97., -165., -232.,  ..., -892., -895., -882.],\n",
      "          [-117., -196., -259.,  ..., -890., -902., -893.],\n",
      "          ...,\n",
      "          [-874., -884., -913.,  ..., -892., -847., -856.],\n",
      "          [-840., -855., -905.,  ..., -877., -870., -887.],\n",
      "          [-842., -831., -871.,  ..., -888., -881., -883.]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-819., -881., -875.,  ...,   20.,   15.,   34.],\n",
      "          [-877., -887., -850.,  ...,  -10.,    5.,   36.],\n",
      "          [-902., -900., -871.,  ...,  -25.,   10.,   36.],\n",
      "          ...,\n",
      "          [-883., -869., -865.,  ...,  631.,  425.,  224.],\n",
      "          [-874., -876., -887.,  ...,  637.,  474.,  276.],\n",
      "          [-864., -886., -895.,  ...,  658.,  522.,  310.]],\n",
      "\n",
      "         [[-886., -900., -901.,  ...,  -67.,  -57.,  -36.],\n",
      "          [-883., -878., -885.,  ...,  -73.,  -59.,  -39.],\n",
      "          [-895., -892., -894.,  ...,  -66.,  -40.,  -34.],\n",
      "          ...,\n",
      "          [-771., -763., -792.,  ...,  225.,  101.,   72.],\n",
      "          [-856., -844., -835.,  ...,  252.,  114.,  104.],\n",
      "          [-897., -880., -863.,  ...,  312.,  135.,   98.]],\n",
      "\n",
      "         [[-889., -900., -890.,  ...,  -93.,  -69.,  -77.],\n",
      "          [-892., -894., -885.,  ...,  -87.,  -62.,  -65.],\n",
      "          [-892., -880., -876.,  ...,  -78.,  -73.,  -73.],\n",
      "          ...,\n",
      "          [-887., -869., -818.,  ...,   83.,  106.,  123.],\n",
      "          [-887., -872., -854.,  ...,   84.,  127.,  140.],\n",
      "          [-857., -836., -825.,  ...,   96.,  111.,  105.]]]]), tensor([0, 1]), '1.3.6.1.4.1.14519.5.2.1.6279.6001.487268565754493433372433148666', (121.152909372, 12.9136003304, -159.399497186))\n"
     ]
    }
   ],
   "source": [
    "print(getitem(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################\n",
    "# subclass Dataset\n",
    "class LunaDataset(Dataset):\n",
    "    def __init__(self, val_stride=0, isValSet_bool=None, series_uid=None):\n",
    "        self.candidateInfo_list = candidateInfo_list.copy()\n",
    "        if series_uid:\n",
    "            self.candidateInfo_list = [\n",
    "                x for x in self.candidateInfo_list if x.series_uid==series_uid\n",
    "            ]\n",
    "        if isValSet_bool:\n",
    "            assert val_stride>0, val_stride\n",
    "            self.candidateInfo_list = self.candidateInfo_list[::val_stride]\n",
    "            assert self.candidateInfo_list\n",
    "        elif val_stride>0:\n",
    "            # delete the validation data get the training data\n",
    "            del self.candidateInfo_list[::val_stride]\n",
    "            assert self.candidateInfo_list\n",
    "            \n",
    "    # the function we need to define\n",
    "    def __len__(self):\n",
    "        return len(self.candidateInfo_list)\n",
    "    \n",
    "    # the function we need to define\n",
    "    def __getitem__(self, ndx):\n",
    "        candidateInfo_tup = self.candidateInfo_list[ndx]\n",
    "        width_irc = (32, 48, 48)\n",
    "        ct_mhd, ct_np = getct(candidateInfo_tup.series_uid)\n",
    "        origin_xyz = ct_mhd.GetOrigin()\n",
    "        vxSize_xyz = ct_mhd.GetSpacing()\n",
    "        direction_a = np.array(ct_mhd.GetDirection()).reshape(3,3)\n",
    "        candidate_a, center_irc = getRawCandidate(candidateInfo_tup.center_xyz,\n",
    "                                                 origin_xyz,\n",
    "                                                 vxSize_xyz,\n",
    "                                                 direction_a,\n",
    "                                                 width_irc, \n",
    "                                                 ct_np)\n",
    "        # transform to tensor\n",
    "        candidate_t = t.from_numpy(candidate_a)\n",
    "        candidate_t = candidate_t.to(t.float32)\n",
    "        # add a new dimension called 'channel'\n",
    "        candidate_t = candidate_t.unsqueeze(0)\n",
    "        # now we should get labels\n",
    "        pos_t = t.tensor([not candidateInfo_tup.isNodule_bool,\n",
    "                         candidateInfo_tup.isNodule_bool],\n",
    "                         # this t.long change true to 1, false to 0\n",
    "                         dtype=t.long)\n",
    "        return (candidate_t, pos_t, \n",
    "                candidateInfo_tup.series_uid, \n",
    "                candidateInfo_tup.center_xyz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  41.,   65.,   69.,  ..., -896., -900., -898.],\n",
       "           [  67.,   70.,   62.,  ..., -889., -899., -916.],\n",
       "           [  65.,   86.,   88.,  ..., -865., -875., -903.],\n",
       "           ...,\n",
       "           [-803., -812., -839.,  ..., -843., -847., -839.],\n",
       "           [-840., -842., -848.,  ..., -824., -830., -817.],\n",
       "           [-831., -839., -849.,  ..., -818., -817., -809.]],\n",
       " \n",
       "          [[  48.,   42.,   22.,  ..., -880., -879., -874.],\n",
       "           [  61.,   47.,   12.,  ..., -899., -885., -882.],\n",
       "           [  42.,   39.,   -1.,  ..., -909., -909., -887.],\n",
       "           ...,\n",
       "           [-853., -867., -872.,  ..., -859., -855., -886.],\n",
       "           [-879., -890., -871.,  ..., -867., -862., -880.],\n",
       "           [-880., -874., -842.,  ..., -882., -866., -860.]],\n",
       " \n",
       "          [[ -30., -109., -195.,  ..., -874., -883., -871.],\n",
       "           [ -97., -165., -232.,  ..., -892., -895., -882.],\n",
       "           [-117., -196., -259.,  ..., -890., -902., -893.],\n",
       "           ...,\n",
       "           [-874., -884., -913.,  ..., -892., -847., -856.],\n",
       "           [-840., -855., -905.,  ..., -877., -870., -887.],\n",
       "           [-842., -831., -871.,  ..., -888., -881., -883.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-819., -881., -875.,  ...,   20.,   15.,   34.],\n",
       "           [-877., -887., -850.,  ...,  -10.,    5.,   36.],\n",
       "           [-902., -900., -871.,  ...,  -25.,   10.,   36.],\n",
       "           ...,\n",
       "           [-883., -869., -865.,  ...,  631.,  425.,  224.],\n",
       "           [-874., -876., -887.,  ...,  637.,  474.,  276.],\n",
       "           [-864., -886., -895.,  ...,  658.,  522.,  310.]],\n",
       " \n",
       "          [[-886., -900., -901.,  ...,  -67.,  -57.,  -36.],\n",
       "           [-883., -878., -885.,  ...,  -73.,  -59.,  -39.],\n",
       "           [-895., -892., -894.,  ...,  -66.,  -40.,  -34.],\n",
       "           ...,\n",
       "           [-771., -763., -792.,  ...,  225.,  101.,   72.],\n",
       "           [-856., -844., -835.,  ...,  252.,  114.,  104.],\n",
       "           [-897., -880., -863.,  ...,  312.,  135.,   98.]],\n",
       " \n",
       "          [[-889., -900., -890.,  ...,  -93.,  -69.,  -77.],\n",
       "           [-892., -894., -885.,  ...,  -87.,  -62.,  -65.],\n",
       "           [-892., -880., -876.,  ...,  -78.,  -73.,  -73.],\n",
       "           ...,\n",
       "           [-887., -869., -818.,  ...,   83.,  106.,  123.],\n",
       "           [-887., -872., -854.,  ...,   84.,  127.,  140.],\n",
       "           [-857., -836., -825.,  ...,   96.,  111.,  105.]]]]),\n",
       " tensor([0, 1]),\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.487268565754493433372433148666',\n",
       " (121.152909372, 12.9136003304, -159.399497186))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we get the same result\n",
    "LunaDataset()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store it in DataLoader\n",
    "trainSet = LunaDataset(val_stride, isValSet_bool=False)\n",
    "batch_size = 16\n",
    "trainLoader = DataLoader(trainSet, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data, label, idd, xyz in trainLoader:\n",
    "    if idd == '1.3.6.1.4.1.14519.5.2.1.6279.6001.487268565754493433372433148666':\n",
    "        print(label)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  41.,   65.,   69.,  ..., -896., -900., -898.],\n",
       "           [  67.,   70.,   62.,  ..., -889., -899., -916.],\n",
       "           [  65.,   86.,   88.,  ..., -865., -875., -903.],\n",
       "           ...,\n",
       "           [-803., -812., -839.,  ..., -843., -847., -839.],\n",
       "           [-840., -842., -848.,  ..., -824., -830., -817.],\n",
       "           [-831., -839., -849.,  ..., -818., -817., -809.]],\n",
       " \n",
       "          [[  48.,   42.,   22.,  ..., -880., -879., -874.],\n",
       "           [  61.,   47.,   12.,  ..., -899., -885., -882.],\n",
       "           [  42.,   39.,   -1.,  ..., -909., -909., -887.],\n",
       "           ...,\n",
       "           [-853., -867., -872.,  ..., -859., -855., -886.],\n",
       "           [-879., -890., -871.,  ..., -867., -862., -880.],\n",
       "           [-880., -874., -842.,  ..., -882., -866., -860.]],\n",
       " \n",
       "          [[ -30., -109., -195.,  ..., -874., -883., -871.],\n",
       "           [ -97., -165., -232.,  ..., -892., -895., -882.],\n",
       "           [-117., -196., -259.,  ..., -890., -902., -893.],\n",
       "           ...,\n",
       "           [-874., -884., -913.,  ..., -892., -847., -856.],\n",
       "           [-840., -855., -905.,  ..., -877., -870., -887.],\n",
       "           [-842., -831., -871.,  ..., -888., -881., -883.]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-819., -881., -875.,  ...,   20.,   15.,   34.],\n",
       "           [-877., -887., -850.,  ...,  -10.,    5.,   36.],\n",
       "           [-902., -900., -871.,  ...,  -25.,   10.,   36.],\n",
       "           ...,\n",
       "           [-883., -869., -865.,  ...,  631.,  425.,  224.],\n",
       "           [-874., -876., -887.,  ...,  637.,  474.,  276.],\n",
       "           [-864., -886., -895.,  ...,  658.,  522.,  310.]],\n",
       " \n",
       "          [[-886., -900., -901.,  ...,  -67.,  -57.,  -36.],\n",
       "           [-883., -878., -885.,  ...,  -73.,  -59.,  -39.],\n",
       "           [-895., -892., -894.,  ...,  -66.,  -40.,  -34.],\n",
       "           ...,\n",
       "           [-771., -763., -792.,  ...,  225.,  101.,   72.],\n",
       "           [-856., -844., -835.,  ...,  252.,  114.,  104.],\n",
       "           [-897., -880., -863.,  ...,  312.,  135.,   98.]],\n",
       " \n",
       "          [[-889., -900., -890.,  ...,  -93.,  -69.,  -77.],\n",
       "           [-892., -894., -885.,  ...,  -87.,  -62.,  -65.],\n",
       "           [-892., -880., -876.,  ...,  -78.,  -73.,  -73.],\n",
       "           ...,\n",
       "           [-887., -869., -818.,  ...,   83.,  106.,  123.],\n",
       "           [-887., -872., -854.,  ...,   84.,  127.,  140.],\n",
       "           [-857., -836., -825.,  ...,   96.,  111.,  105.]]]]),\n",
       " tensor([0, 1]),\n",
       " '1.3.6.1.4.1.14519.5.2.1.6279.6001.487268565754493433372433148666',\n",
       " (121.152909372, 12.9136003304, -159.399497186))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainLoader.dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
